{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import avstack  # need to import to set the registriesc\n",
    "import avapi  # need to import to set the registries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avapi.carla import CarlaScenesManager\n",
    "from avapi.kitti import KittiScenesManager\n",
    "from avapi.nuscenes import nuScenesManager\n",
    "\n",
    "dataset = \"kitti\"\n",
    "\n",
    "if dataset == \"nuscenes\":\n",
    "    nusc_data_dir = \"../data/nuScenes\"\n",
    "    SM = nuScenesManager(nusc_data_dir)\n",
    "    SD = SM.get_scene_dataset_by_name(\"scene-0103\")\n",
    "    ds_name = \"nuscenes\"\n",
    "    agent_name = None\n",
    "    cam_name = \"main_camera\"\n",
    "    lid_name = \"main_lidar\"\n",
    "elif dataset == \"kitti\":\n",
    "    kitti_obj_data_dir = \"../data/KITTI/object/\"\n",
    "    kitti_raw_data_dir = \"../data/KITTI/raw\"\n",
    "    SM = KittiScenesManager(kitti_obj_data_dir, kitti_raw_data_dir)\n",
    "    SD = SM.get_scene_dataset_by_index(0)\n",
    "    ds_name = \"kitti\"\n",
    "    agent_name = None\n",
    "    cam_name = \"main_camera\"\n",
    "    lid_name = \"main_lidar\"\n",
    "elif dataset == \"carla\":\n",
    "    carla_data_dir = \"../data/CARLA/multi-agent-v1/\"\n",
    "    SM = CarlaScenesManager(data_dir=carla_data_dir)\n",
    "    SD = SM.get_scene_dataset_by_index(1)\n",
    "    ds_name = \"carla-vehicle\"\n",
    "    agent_name = 0\n",
    "    cam_name = \"camera-0\"\n",
    "    lid_name = \"lidar-0\"\n",
    "else:\n",
    "    raise NotImplementedError(dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Perception and Object Tracking\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run perception and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avstack.geometry import GlobalOrigin3D\n",
    "from avstack.modules.perception.object3d import MMDetObjectDetector3D\n",
    "from avstack.modules.tracking.tracker3d import BasicBoxTracker3D\n",
    "\n",
    "# Load models\n",
    "perception = MMDetObjectDetector3D(model=\"pointpillars\", dataset=ds_name)\n",
    "tracker = BasicBoxTracker3D(check_reference=False)\n",
    "\n",
    "# look over all frames from a scene\n",
    "first_frame = 1\n",
    "last_frame = 20\n",
    "all_imgs = []\n",
    "all_times = []\n",
    "all_truths = []\n",
    "all_dets = []\n",
    "all_tracks = []\n",
    "frames = SD.get_frames(sensor=cam_name, agent=agent_name)\n",
    "for frame in frames[first_frame:last_frame]:\n",
    "    # get data\n",
    "    ts = SD.get_timestamp(frame)\n",
    "    all_times.append(ts)\n",
    "    img = SD.get_image(frame=frame, sensor=cam_name, agent=agent_name)\n",
    "    all_imgs.append(img)\n",
    "    pc = SD.get_lidar(frame=frame, sensor=lid_name, agent=agent_name)\n",
    "    gt_objects_global = SD.get_objects(frame, sensor=lid_name, agent=agent_name, in_global=True)\n",
    "    all_truths.append(gt_objects_global)\n",
    "\n",
    "    # run inference\n",
    "    dets_local = perception(pc)\n",
    "    dets_global = dets_local.apply_and_return(\"change_reference\", GlobalOrigin3D, inplace=False)\n",
    "    all_dets.append(dets_global)\n",
    "    tracks_global = tracker(dets_global, platform=GlobalOrigin3D)\n",
    "    all_tracks.append(tracks_global)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avapi.evaluation.ospa import OspaMetric\n",
    "from avstack.modules.assignment import gnn_single_frame_assign\n",
    "\n",
    "# parameters for evaluation\n",
    "assign_radius = 2.0\n",
    "n_tru = []\n",
    "n_trk = []\n",
    "n_asg = []\n",
    "ospas = []\n",
    "\n",
    "# run evaluation for every frame\n",
    "for truths, tracks in zip(all_truths, all_tracks):\n",
    "    x_truths = [tru.position.x for tru in truths]\n",
    "    x_tracks = [trk.position.x for trk in tracks]\n",
    "    A = np.array(\n",
    "        [[np.linalg.norm(l1 - l2) for l1 in x_tracks] for l2 in x_truths]\n",
    "    )\n",
    "    assign = gnn_single_frame_assign(A, cost_threshold=assign_radius)\n",
    "    n_tru.append(len(x_truths))\n",
    "    n_trk.append(len(x_tracks))\n",
    "    n_asg.append(len(assign))\n",
    "    ospas.append(OspaMetric.cost(tracks=x_tracks, truths=x_truths, c=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from avapi.visualize.snapshot import show_image_with_boxes\n",
    "\n",
    "# ===========================================\n",
    "# show a frame\n",
    "# ===========================================\n",
    "frame = 18\n",
    "show_image_with_boxes(all_imgs[frame], all_truths[frame], inline=True)\n",
    "show_image_with_boxes(all_imgs[frame], all_dets[frame], inline=True)\n",
    "show_image_with_boxes(all_imgs[frame], all_tracks[frame], inline=True)\n",
    "\n",
    "# ===========================================\n",
    "# show metrics\n",
    "# ===========================================\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,10))\n",
    "\n",
    "# first: assignments\n",
    "axs[0].plot(all_times, n_tru, marker=\"o\", linestyle=\"--\", label=\"Num Truths\")\n",
    "axs[0].plot(all_times, n_trk, marker=\"o\", linestyle=\"--\", label=\"Num Tracks\")\n",
    "axs[0].plot(all_times, n_asg, marker=\"o\", linestyle=\"--\", label=\"Num Assignments\")\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel(\"Time (s)\")\n",
    "axs[0].set_ylabel(\"Metric\")\n",
    "axs[0].set_title(\"Number of Truths, Tracks, and Assignments\")\n",
    "\n",
    "# second: OSPA\n",
    "axs[1].plot(all_times, ospas, marker=\"o\", linestyle=\"--\")\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "axs[1].set_ylabel(\"Metric\")\n",
    "axs[1].set_title(\"Optimal Subpattern Assignment (lower = better)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-autonomy-UkJ15zkC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "acac73ce11a26a1ce64757f7e20c81075aae92671fc9818b61cdda2c31af35e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
